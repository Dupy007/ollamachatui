Voici un **README.md** complet pour votre projet, incluant une illustration et toutes les informations nÃ©cessaires pour son utilisation et son dÃ©ploiement :

---

# Chat Interface with Ollama Models

![Chat Interface Illustration](.images/screen.png)

---

## ğŸ“ Description

Ce projet est une interface web pour interagir avec des modÃ¨les de langage hÃ©bergÃ©s localement. 

Il permet de :
   - Choisir parmi plusieurs modÃ¨les disponibles (ex: TinyLlama, Llama2, etc.).
   - Dialoguer en temps rÃ©el avec le modÃ¨le sÃ©lectionnÃ©.
   - Sauvegarder la conversation en session pendant 1 heure.
   - Afficher les rÃ©ponses en streaming pour une expÃ©rience fluide.

---

## ğŸš€ FonctionnalitÃ©s

- **SÃ©lection de modÃ¨le** : Choisissez parmi les modÃ¨les disponibles sur votre instance Ollama.
- **Conversation persistante** : La conversation est sauvegardÃ©e en session pendant 1 heure.
- **Streaming des rÃ©ponses** : Les rÃ©ponses du modÃ¨le sont affichÃ©es en temps rÃ©el.
- **Interface intuitive** : Design moderne et rÃ©actif.
- **Gestion des erreurs** : Messages d'erreur clairs en cas de problÃ¨me.

---

## ğŸ› ï¸ Installation

### PrÃ©requis

- PHP 8.0 ou supÃ©rieur
- Ollama installÃ© et configurÃ© localement
- Un navigateur web moderne

### Ã‰tapes d'installation

1. **Cloner le dÃ©pÃ´t :**
   ```bash
   git clone https://github.com:Dupy007/ollamachatui.git
   cd ollamachatui
   ```

2. **DÃ©marrer Ollama :**
   Assurez-vous qu'Ollama est en cours d'exÃ©cution :
   ```bash
   ollama serve
   ```

3. **DÃ©marrer le serveur PHP :**
   ```bash
   php -S localhost:8000
   ```

4. **AccÃ©der Ã  l'interface :**
   Ouvrez votre navigateur et accÃ©dez Ã  :
   ```
   http://localhost:8000
   ```

---

## ğŸ–¥ï¸ Utilisation

1. **SÃ©lectionnez un modÃ¨le** dans le menu dÃ©roulant en haut de l'interface.
2. **Tapez votre message** dans la zone de texte et appuyez sur EntrÃ©e ou cliquez sur "Envoyer".
3. **Observez la rÃ©ponse** du modÃ¨le en temps rÃ©el.
4. **L'historique** de la conversation est automatiquement sauvegardÃ© pendant 1 heure.

---

## ğŸ§© Structure du projet

```
ollamachatui/
â”œâ”€â”€ index.php          # Interface principale
â”œâ”€â”€ api.php            # Backend pour les requÃªtes Ollama
â”œâ”€â”€ get_models.php     # RÃ©cupÃ¨re la liste des modÃ¨les disponibles
â”œâ”€â”€ set_model.php      # Change le modÃ¨le sÃ©lectionnÃ©
â”œâ”€â”€ style.css          # Feuille de style
â”œâ”€â”€ script.js          # Script JavaScript pour l'interactivitÃ©
â””â”€â”€ README.md          # Ce fichier
```

---

## âš™ï¸ Configuration

### Variables d'environnement

Vous pouvez configurer le projet via des variables d'environnement :

```bash
export OLLAMA_HOST="http://localhost:11434"
export OLLAMA_ORIGINS="*"
export PHP_MAX_EXECUTION_TIME=600
```

### Options avancÃ©es

- **Changer le port PHP** :
  ```bash
  php -S localhost:8080
  ```

- **Modifier le timeout de session** :
  Dans `api.php`, modifiez :
  ```php
  if (time() - $lastActivity > 3600) { // 3600 secondes = 1 heure
  ```

---

## ğŸ› DÃ©pannage

### Erreurs courantes

1. **ModÃ¨le non disponible** :
   - VÃ©rifiez que le modÃ¨le est bien tÃ©lÃ©chargÃ© :
     ```bash
     ollama list
     ```
   - Si nÃ©cessaire, tÃ©lÃ©chargez-le :
     ```bash
     ollama pull tinyllama
     ```

2. **ProblÃ¨mes de connexion** :
   - VÃ©rifiez qu'Ollama est en cours d'exÃ©cution :
     ```bash
     curl http://localhost:11434/api/tags
     ```

3. **Timeout PHP** :
   - Augmentez le temps d'exÃ©cution maximum dans `api.php` :
     ```php
     set_time_limit(600); // 10 minutes
     ```

---

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

---

## ğŸ™ Contribution

Les contributions sont les bienvenues !

---

## ğŸ“¸ Capture d'Ã©cran

![Exemple d'interface](.images/screen.png)

---
